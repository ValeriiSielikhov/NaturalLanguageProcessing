{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "treated-hierarchy",
   "metadata": {},
   "source": [
    "**4.4.3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "useful-appraisal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 3.],\n",
      "        [1., 3., 3.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "in_ = torch.tensor([[[1, 0 , 2], [0, 1, 3], [1, 3 , 0]]], dtype=float)\n",
    "m = torch.nn.MaxPool1d(2, stride=1)\n",
    "in_[0] = in_[0].t()\n",
    "t = m(in_)\n",
    "print(t[0].t())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-barrel",
   "metadata": {},
   "source": [
    "**4.4.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "leading-desktop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 1.0000, 1.2500]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "in_ = torch.tensor([[[1, 0 , 2], [0, 1, 3], [1, 3 , 0], [0, 0, 0]]], dtype=float)\n",
    "k = in_.shape[1]\n",
    "m = torch.nn.AvgPool1d(k)\n",
    "in_ = torch.transpose(in_, 1, 2)\n",
    "t = m(in_)\n",
    "print(t[0].t())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-cleveland",
   "metadata": {},
   "source": [
    "**4.4.7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "understood-circumstances",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4 1.4 1.7]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([[1, 0 , 2], [0, 1, 3], [1, 3 , 0], [0, 0, 0]])\n",
    "att_scores=np.array([0.1, 0.5, 0.3, 0.1])\n",
    "print(att_scores.T.dot(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-machine",
   "metadata": {},
   "source": [
    "**4.4.10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "charitable-speaking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2846199129072058 0.7832351376612332 2.5457424606716965\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import exp\n",
    "\n",
    "Input = np.array([[1, 0, 2], [0, 1, 3], [1, 3, 0], [0, 0, 0]])\n",
    "Query = np.array([0, 0, 1])\n",
    "\n",
    "unnorm_scores = Input @ Query\n",
    "\n",
    "att_scores = exp(unnorm_scores) / sum(exp(unnorm_scores))\n",
    "print(*att_scores @ Input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-kitchen",
   "metadata": {},
   "source": [
    "**4.5.4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "serious-track",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0]\n",
      " [0 1 1 0]\n",
      " [1 1 2 0]\n",
      " [0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[1, 0], [0,1], [1,1], [0,0]])\n",
    "print(a@a.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-documentation",
   "metadata": {},
   "source": [
    "**4.5.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "published-board",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.73105858 0.5       ]\n",
      " [0.5        0.73105858]\n",
      " [0.73105858 0.73105858]\n",
      " [0.5        0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "\n",
    "a = np.array([[1, 0], [0,1], [1,1], [0,0]])\n",
    "logic = a@a.T\n",
    "logic_norm = scipy.special.softmax(logic, axis=1)\n",
    "print(logic_norm@a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-tampa",
   "metadata": {},
   "source": [
    "**4.5.7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "primary-bridal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5        0.5       ]\n",
      " [0.73105858 0.5       ]\n",
      " [0.73105858 0.5       ]\n",
      " [0.5        0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "\n",
    "input_ = np.array([[1, 0], [0,1], [1,1], [0,0]])\n",
    "proj_q = np.array([[0,0],[1,0]])\n",
    "proj_k = np.array([[1,0],[0,0]])\n",
    "proj_v = np.array([[1,0],[0,1]])\n",
    "\n",
    "key = input_@proj_k\n",
    "value = input_@proj_v\n",
    "queries = input_@proj_q\n",
    "\n",
    "logic = queries@key.T\n",
    "all_score = scipy.special.softmax(logic, axis=1)\n",
    "result = all_score@value\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-bread",
   "metadata": {},
   "source": [
    "**4.5.9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "occasional-tongue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5        0.73105858 0.73105858 0.5       ]\n",
      "[0.73105858 0.73105858 0.88079708 0.5       ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "\n",
    "input_ = np.array([[1, 0], [0,1], [1,1], [0,0]])\n",
    "proj_q1 = np.array([[0,1],[1,0]])\n",
    "proj_k1 = np.array([[1,0],[0,0]])\n",
    "proj_v1 = np.array([1,0])\n",
    "proj_q2 = np.array([[1,1],[1,1]])\n",
    "proj_k2 = np.array([[0,0],[1,0]])\n",
    "proj_v2 = np.array([0,1])\n",
    "\n",
    "key1 = input_@proj_k1\n",
    "value1 = input_@proj_v1\n",
    "queries1 = input_@proj_q1\n",
    "key2 = input_@proj_k2\n",
    "value2 = input_@proj_v2\n",
    "queries2 = input_@proj_q2\n",
    "\n",
    "logic1 = queries1@key1.T\n",
    "logic2 = queries2@key2.T\n",
    "all_score1 = scipy.special.softmax(logic1, axis=1)\n",
    "all_score2 = scipy.special.softmax(logic2, axis=1)\n",
    "result1 = all_score1@value1\n",
    "result2 = all_score2@value2\n",
    "print(result1)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-tract",
   "metadata": {},
   "source": [
    "**4.7.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "constitutional-capitol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8106187774962709, 0.4395507898340978, 0.8290096270213004, 0.20134327995534496], [0.938964520620817, 0.4395507898340978, 0.8290096270213004, 0.07860176987690048], [0.938964520620817, 0.6411287103553837, 0.509253427569025, 0.7094441369109541], [0.691552879511939, 0.6411287103553837, 0.509253427569025, 0.7631262538014161]]\n",
      "[[1.0, 1.0, 1.0, 0.0], [1.0, 0.0, 0.0, 1.0], [0.0, 1.0, 1.0, 1.0], [1.0, 0.0, 0.0, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def write_array(arr):\n",
    "    print(repr(arr.tolist()))\n",
    "    \n",
    "    \n",
    "def max_pooling(features, kernel_size):\n",
    "    \"\"\"\n",
    "    features - InLen x EmbSize - features of elements of input sequence\n",
    "    kernel_size - positive integer - size of sliding window\n",
    "\n",
    "    returns tuple of two matrices of shape OutLen x EmbSize:\n",
    "         - output features (main result)\n",
    "         - relative indices of maximum elements for each position of sliding window\n",
    "    \"\"\"\n",
    "    dim0, dim1 = features.shape[0]-kernel_size+1, features.shape[1]\n",
    "    result = np.zeros(shape = (dim0, dim1))\n",
    "    indices = np.zeros(shape = (dim0, dim1))\n",
    "    for i in range(dim0):\n",
    "        result[i] = np.max(features[i:i+kernel_size], axis=0)\n",
    "        indices[i] = np.argmax(features[i:i+kernel_size], axis=0)\n",
    "    \n",
    "    return result, indices\n",
    "\n",
    "\n",
    "features = np.array([[0.6046018907385543, 0.0812964077275945, 0.6366439552273822, 0.20134327995534496],\n",
    "                     [0.8106187774962709, 0.4395507898340978, 0.8290096270213004, 0.05773841312522798],\n",
    "                     [0.938964520620817, 0.3860407857274528, 0.21318174478828456, 0.07860176987690048],\n",
    "                     [0.04840110723428537, 0.6411287103553837, 0.509253427569025, 0.7094441369109541],\n",
    "                     [0.691552879511939, 0.4979735285634219, 0.07060470682483455, 0.7631262538014161]])\n",
    "kernel_size = 2\n",
    "\n",
    "result, indices = max_pooling(features, kernel_size)\n",
    "\n",
    "write_array(result)\n",
    "write_array(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-boxing",
   "metadata": {},
   "source": [
    "**4.7.3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "preceding-companion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.0, 0.7454337173675266, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, -2.1273406024899657, 0.0, 0.0], [-0.0763791951131031, 0.0, 0.0, 0.0], [0.0, 0.0, -1.0015622079642417, -2.508470377801969], [0.0, 0.0, 0.0, 0.0], [-0.9080189656976042, 0.0, 0.0, 2.2803247286304087], [-0.7771529142648868, 0.0, 0.0, 0.0], [0.0, -2.371055190136431, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def parse_array(s):\n",
    "    return np.array(ast.literal_eval(s))\n",
    "\n",
    "def read_array():\n",
    "    return parse_array(sys.stdin.readline())\n",
    "\n",
    "def write_array(arr):\n",
    "    print(repr(arr.tolist()))\n",
    "\n",
    "\n",
    "def max_pooling_dldfeatures(features, kernel_size, indices, dldout):\n",
    "    \"\"\"\n",
    "    features - InLen x EmbSize - features of elements of input sequence\n",
    "    kernel_size - positive integer - size of sliding window\n",
    "    indices - OutLen x EmbSize - relative indices of maximum elements for each window position\n",
    "    dldout - OutLen x EmbSize - partial derivative of loss function with respect to outputs of max_pooling layer\n",
    "\n",
    "    returns InLen x EmbSize\n",
    "    \"\"\"\n",
    "    dim0, dim1 = indices.shape\n",
    "    \n",
    "    result = np.zeros(features.shape)\n",
    "    for i in range(dim0):\n",
    "        for j in range(dim1):\n",
    "            result[i+indices[i,j],j] += dldout[i,j]\n",
    "    return result\n",
    "\n",
    "\n",
    "features = np.array([[-1.2420542766989977, -0.045100789663994285, 1.858151857421511, 0.10732741246325356],\n",
    "                     [-1.480497780371414, -0.12486054931133332, -0.18422425981847368, -1.4228130362490647],\n",
    "                     [-0.8417536968892625, 0.9802583655274091, -0.18413492661665792, -1.5582607186399924],\n",
    "                     [1.325799250424393, 0.08149768959330334, -1.454876921308986, 0.1408031456023352],\n",
    "                     [0.1637602967235608, -0.21250114632967532, 0.8362859721448469, 0.717774697701287],\n",
    "                     [-0.7641399532198978, -2.112568530488304, 0.20121440705964902, 0.015624280892385661],\n",
    "                     [1.3862200103422582, 0.6508694196448389, -1.162417318743681, 1.5202488401790915],\n",
    "                     [1.3947418297193952, -1.013483406336198, -2.0608332074129545, -1.733019236247151],\n",
    "                     [1.0932612618870112, 0.8071262618398916, 0.15924519176972282, -0.6885825807454318]])\n",
    "\n",
    "kernel_size = 6\n",
    "indices = np.array([[3.0, 2.0, 0.0, 4.0],\n",
    "                    [5.0, 1.0, 3.0, 5.0],\n",
    "                    [5.0, 0.0, 2.0, 4.0],\n",
    "                    [4.0, 5.0, 1.0, 3.0]]).astype('uint32')\n",
    "\n",
    "dldout = np.array([[-0.0763791951131031, -0.8729161683329371, 0.7454337173675266, -2.508470377801969],\n",
    "                   [-0.9080189656976042, 0.6952579391985969, 0.2829942797947518, 0.35396918585149195],\n",
    "                   [0.339009358836277, -1.9496823733556254, -0.11017174942549533, 1.4591363247582954],\n",
    "                   [-1.1161622731011638, -2.371055190136431, -1.174384738333498, 0.4672192180206214]])\n",
    "\n",
    "dldfeatures = max_pooling_dldfeatures(features, kernel_size, indices, dldout)\n",
    "\n",
    "write_array(dldfeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-serbia",
   "metadata": {},
   "source": [
    "**4.7.4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "public-delay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06860598204389033, 0.03703718180652343, 0.06169051603553571, 0.006999663809155501, 0.02530593948353462, 0.02723806143745914, 0.040806327204274295, 0.019262891730251305, 0.18134764032840614, 0.01644130749673833, 0.007109074723334883, 0.03555704949423753, 0.033931576448048006, 0.0267173505099923, 0.032210162471156406, 0.25362223807297396, 0.028250079060620836, 0.09786695784386741]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def write_array(arr):\n",
    "    print(repr(arr.tolist()))\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    x - vector of n elements - input\n",
    "\n",
    "    returns vector of n elements - softmax output\n",
    "    \"\"\"\n",
    "    return np.exp(x)/np.sum(np.exp(x))\n",
    "\n",
    "\n",
    "x = np.array([0.7903253367110061, 0.1738679257213426, 0.6840758121402977, -1.4921922753864911, -0.20701526564877176, -0.13343908330179777, 0.27078275189785883, -0.47987385916752834, 1.762361457920409, -0.6382574781276095, -1.476682298043406, 0.13308403857533435, 0.08629164346752129, -0.15274120983311792, 0.03422761142701722, 2.0977915122558075, -0.09695813983037735, 1.145554587286743])\n",
    "\n",
    "result = softmax(x)\n",
    "\n",
    "write_array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-mixture",
   "metadata": {},
   "source": [
    "**4.7.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "democratic-control",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.36170314084137395, 1.531638983431016, -1.7131284538840788, -0.9027503682845508, -0.8591376176087115, 0.16481576122888014, 0.2286590883015934, 0.4686776665093307, -0.4880318948728026, 0.13865483857501165, -1.0740873577508447, -1.1693607815929845, 0.6388250392697977]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def parse_array(s):\n",
    "    return np.array(ast.literal_eval(s))\n",
    "\n",
    "def read_array():\n",
    "    return parse_array(sys.stdin.readline())\n",
    "\n",
    "def write_array(arr):\n",
    "    print(repr(arr.tolist()))\n",
    "\n",
    "\n",
    "def dsoftmax_dx(x):\n",
    "    \"\"\"\n",
    "    x - vector of n elements - input\n",
    "\n",
    "    returns matrix n x n\n",
    "    \"\"\"\n",
    "    softmax = np.exp(x)/np.sum(np.exp(x))\n",
    "    s = softmax.reshape(-1,1)\n",
    "    return np.diagflat(s) - np.dot(s, s.T)\n",
    "\n",
    "\n",
    "x = np.array([-0.36170314084137395, 1.531638983431016, -1.7131284538840788, -0.9027503682845508, -0.8591376176087115, 0.16481576122888014, 0.2286590883015934, 0.4686776665093307, -0.4880318948728026, 0.13865483857501165, -1.0740873577508447, -1.1693607815929845, 0.6388250392697977])\n",
    "\n",
    "result = dsoftmax_dx(x)\n",
    "\n",
    "write_array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-corruption",
   "metadata": {},
   "source": [
    "**4.7.6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ultimate-marketplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4740581778159266, 0.34432834551260527, 0.4665167530554427, 0.6711507992179182, 0.3014932578908269, 0.5216013512810533, 0.5739206841874827, 0.5011664230502015, 0.6659426824711601, 0.5870403517141656, 0.48456045445664914, 0.5519092842133653, 0.6631513043916591, 0.6203158151313123, 0.6799614219857059]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def write_array(arr):\n",
    "    print(repr(arr.tolist()))\n",
    "\n",
    "\n",
    "def attention(features, query):\n",
    "    \"\"\"\n",
    "    features - InLen x EmbSize - features of elements of input sequence\n",
    "    query - EmbSize - features of query object\n",
    "\n",
    "    returns vector of size EmbSize - features, aggregated according to the query\n",
    "    \"\"\"\n",
    "    score = features@query\n",
    "    norm_score = np.exp(score )/np.sum(np.exp(score))\n",
    "    return norm_score@features\n",
    "\n",
    "\n",
    "features = np.array([[0.3504305689198156, 0.871844425624726, 0.29345316540775357, 0.49159320438393916, 0.16391992930609034, 0.24589641847050037, 0.34921020303336925, 0.09968814035867879, 0.8652385667745919, 0.00906484385602968, 0.6134586521086117, 0.08104312584086149, 0.643129733435556, 0.6610968673257929, 0.6825169003800382], [0.005641686042561211, 0.3397733866278605, 0.4408793722092307, 0.6618752692611525, 0.4192615374283991, 0.6718589897811911, 0.23503584107912667, 0.9972834040264165, 0.6907780153811639, 0.5160598448726361, 0.4200243418824855, 0.7745997472321381, 0.9124177261957108, 0.627661131744206, 0.7792319239076758], [0.44947044223343224, 0.39851993627332394, 0.27645205987950927, 0.3360502940952873, 0.20207394761469466, 0.27730469648938627, 0.9647449489128369, 0.38480306917172535, 0.7014748335636187, 0.5616919724157547, 0.3082991954077743, 0.43320540280287834, 0.7682716834674514, 0.04669826413239708, 0.7975639937877288], [0.3529089999231677, 0.5085801437940869, 0.6686697864089949, 0.9579051761714787, 0.14893344048972235, 0.6504801381978066, 0.6554087909852483, 0.2182290972559655, 0.8874805349214916, 0.8549111586624765, 0.2256959432511686, 0.7090739886051667, 0.9215898392742404, 0.8361038069049278, 0.9807575571901945], [0.93096165894251, 0.21204415175966806, 0.005393301311816812, 0.6868163541395496, 0.17651743121260177, 0.4276211882347165, 0.7172630747046246, 0.6222321154458413, 0.782866044726867, 0.9401403417712956, 0.6009251310321828, 0.7689712777389628, 0.011137370287858661, 0.6750220130270511, 0.3656918897133191], [0.344423832576648, 0.5200078573131781, 0.08090528060543856, 0.6187002344784092, 0.24428489996011238, 0.18400539459399, 0.40308101020726217, 0.19255989698913867, 0.8010944590934469, 0.20324438899818598, 0.4927144298170735, 0.03783988662477278, 0.7705093963091103, 0.2520865403496373, 0.40266725180440743], [0.6681310493060861, 0.2801674372250399, 0.6224648405839522, 0.6287746784150413, 0.864080498689899, 0.23833127705610258, 0.20311743810136906, 0.6646132937899738, 0.23575457417289924, 0.1869625695994146, 0.7712148738157554, 0.15237041670323637, 0.2763150373902683, 0.46500408886101585, 0.991468614310106], [0.47955269815875845, 0.18371674117676162, 0.4749895427072034, 0.5127159626377625, 0.14327300286458633, 0.5921086963579639, 0.21467664382766927, 0.08984875049424312, 0.5619088573772313, 0.6324525220346037, 0.65145500723789, 0.5118736033583858, 0.3791794826772541, 0.7062193547285907, 0.12888775429739185], [0.8936198110390413, 0.1499351596848777, 0.23230300209801535, 0.6275970485906217, 0.14179412142521963, 0.44590423506527455, 0.6398118989481705, 0.44025473834142315, 0.9690917160909921, 0.7329911430579539, 0.4723409208689966, 0.30051845327308735, 0.6517065287372249, 0.11682964074366375, 0.3356912564688531], [0.5819483213886298, 0.12715730125007862, 0.6624081011547434, 0.27210122174739293, 0.3321414469174103, 0.6738692045564213, 0.49979407643990537, 0.923095453187033, 0.8688108133354637, 0.29672803800781, 0.8422355709858387, 0.22967466587429908, 0.48606633908371566, 0.3302629931498261, 0.9271715208940098], [0.814229644181095, 0.6269508015754929, 0.19067116118180638, 0.6597416333912787, 0.3042396495694798, 0.5349586078017191, 0.9889297007928726, 0.5059647631701082, 0.6586214714303461, 0.19972197385065704, 0.730120041302739, 0.9254129585548022, 0.7774768791337286, 0.5880525770183761, 0.4404909426586451], [0.8393608070151912, 0.551470751477307, 0.3776646281929925, 0.7403545806778788, 0.01464073752506101, 0.49682079457661743, 0.12829037985166736, 0.8323709714882789, 0.4861583628986299, 0.10966510942571872, 0.36384711262095637, 0.008343156485128067, 0.05481969871494197, 0.11036480291979456, 0.3495717657917], [0.575668909069271, 0.1948209406820347, 0.5066632418120769, 0.5610866065811511, 0.7503051258152065, 0.20250301475454058, 0.9387177222181186, 0.4214964558859865, 0.2441688535705906, 0.2852282954051667, 0.7185375048873539, 0.09961745251862686, 0.507873295740294, 0.9713796833363287, 0.8218946227484244], [0.14519733396011691, 0.07264015089790021, 0.7254237309701331, 0.7437297525624584, 0.3465971472185204, 0.6489212261982703, 0.2152569561085349, 0.6476151760429897, 0.2045187871395916, 0.9599712380254137, 0.28554199184758966, 0.7701922251424572, 0.7095119328780166, 0.7579558453415812, 0.4251898428876446]])\n",
    "query = np.array([0.30760147020407946, 0.1528992448227442, 0.9387231083505163, 0.12201982125460176, 0.3159744925438269, 0.555332538642272, 0.8654043562058316, 0.5523485724329922, 0.6405492495162189, 0.8421217300945876, 0.03415012932624606, 0.0914780538557024, 0.745151636966557, 0.9885343010237021, 0.02289480154711454])\n",
    "\n",
    "result = attention(features, query)\n",
    "\n",
    "write_array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-collector",
   "metadata": {},
   "source": [
    "**4.7.7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "wrapped-crystal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.3828516277455325, -0.7052491362196254], [1.2990231347325174, 0.07313412990950192], [1.7291639000678212, 0.05709755596284554], [4.997749368650844, 0.9611194260544592], [4.920776273177981, 0.9417305419570735], [5.027240226701747, 0.9675417617162316], [5.008405848246054, 0.9647146788718595], [4.617706670795201, 0.8915957294670733], [5.018586540911719, 0.9660416945021237], [1.412170986514584, -1.008285421305741], [0.8082085153678322, -0.02863474439053919], [4.261630070405552, 0.7878600291134993], [1.1488305812076607, -1.1882802581002714], [1.192908066935946, -1.220148314614849], [3.9068303877684643, 0.7744398548226674]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def parse_array(s):\n",
    "    return np.array(ast.literal_eval(s))\n",
    "\n",
    "def read_array():\n",
    "    return parse_array(sys.stdin.readline())\n",
    "\n",
    "def write_array(arr):\n",
    "    print(repr(arr.tolist()))\n",
    "\n",
    "\n",
    "def self_attention(features, proj_k, bias_k, proj_q, bias_q, proj_v, bias_v):\n",
    "    \"\"\"\n",
    "    features - InLen x EmbSize - features of elements of input sequence\n",
    "    proj_k - EmbSize x EmbSize - projection matrix to make keys from features\n",
    "    bias_k - EmbSize - bias vector to make keys from features\n",
    "    proj_q - EmbSize x EmbSize - projection matrix to make queries from features\n",
    "    bias_q - EmbSize - bias vector to make queries from features\n",
    "    proj_v - EmbSize x EmbSize - projection matrix to make values from features\n",
    "    bias_v - EmbSize - bias vector to make values from features\n",
    "\n",
    "    returns InLen x EmbSize\n",
    "    \"\"\"\n",
    "    def softmax(x, axis=None):\n",
    "        e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "        return e_x / np.sum(e_x, axis=axis, keepdims=True)\n",
    "                    \n",
    "    key = features@proj_k + bias_k\n",
    "    queries = features@proj_q + bias_q\n",
    "    value = features@proj_v + bias_v\n",
    "    \n",
    "    logic = queries@key.T\n",
    "    norm_logic = softmax(logic, 1)\n",
    "    \n",
    "    return norm_logic@value\n",
    "\n",
    "\n",
    "features = np.array([[0.5175129778200084, 0.13021330700949507],\n",
    "                     [-0.3578609445921744, -0.07768163060380659],\n",
    "                     [-0.046577477754636734, -0.12288550821838619],\n",
    "                     [0.4424092505449793, -1.431399548551344],\n",
    "                     [0.753992222548331, -1.1210257338970167],\n",
    "                     [1.6736061037504428, -1.9789731491226337],\n",
    "                     [-1.4985152255486565, -1.6614802556117283],\n",
    "                     [-0.610065708073959, -0.8475335063027695],\n",
    "                     [-0.1657640783522184, -1.7079776825852762],\n",
    "                     [0.7857341373616981, 0.2956255012408635],\n",
    "                     [-0.49243028413686984, 0.01065675311085114],\n",
    "                     [0.20598401523943788, -0.6339670563637549],\n",
    "                     [-0.15698934123474126, 0.9516567843056503],\n",
    "                     [-0.08965595798444444, 0.9923765422389716],\n",
    "                     [-0.9649404480809814, -0.6203623955866846]])\n",
    "\n",
    "proj_k = np.array([[-0.4777373377067222, 1.384780896738418],\n",
    "                   [1.5537173245233542, -1.6151073640132454]])\n",
    "\n",
    "bias_k = np.array([0.34068677065672126, -1.7225350645946451])\n",
    "\n",
    "proj_q = np.array([[1.667192089239799, 0.9072106203091014],\n",
    "                   [1.0017863742909645, -0.8578876449703756]])\n",
    "\n",
    "bias_q = np.array([-0.3811843050970959, -0.15922065479353645])\n",
    "\n",
    "proj_v = np.array([[2.396375885002737, 0.23995979796695774],\n",
    "                   [0.21631803999882093, -0.6475173781192963]])\n",
    "\n",
    "bias_v = np.array([1.448781271879823, -0.7144164516316529])\n",
    "\n",
    "result = self_attention(features, proj_k, bias_k, proj_q, bias_q, proj_v, bias_v)\n",
    "\n",
    "write_array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-challenge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
